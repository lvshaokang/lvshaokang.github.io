<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="为什么要改变HDFS tmp 文件存储目录&amp;整理块大小、副本数、小文件的理解&amp;整理HDFS架构&amp;整理SNN流程"><meta name="keywords" content="HDFS,Hadoop"><meta name="author" content="Red"><meta name="copyright" content="Red"><title>为什么要改变HDFS tmp 文件存储目录&amp;整理块大小、副本数、小文件的理解&amp;整理HDFS架构&amp;整理SNN流程 | RedのBlog</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script><meta name="generator" content="Hexo 4.1.0"></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#目标"><span class="toc-number">1.</span> <span class="toc-text">目标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#为什么要改变HDFS-tmp-存储目录"><span class="toc-number">2.</span> <span class="toc-text">为什么要改变HDFS &#x2F;tmp 存储目录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#整理块大小、副本数的理解"><span class="toc-number">3.</span> <span class="toc-text">整理块大小、副本数的理解</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#块大小"><span class="toc-number">3.1.</span> <span class="toc-text">块大小</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#副本数"><span class="toc-number">3.2.</span> <span class="toc-text">副本数</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#整理小文件的理解"><span class="toc-number">4.</span> <span class="toc-text">整理小文件的理解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#整理HDFS的架构"><span class="toc-number">5.</span> <span class="toc-text">整理HDFS的架构</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#NameNode"><span class="toc-number">5.1.</span> <span class="toc-text">NameNode</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#DataNode"><span class="toc-number">5.2.</span> <span class="toc-text">DataNode</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#SecondeayNameNode"><span class="toc-number">5.3.</span> <span class="toc-text">SecondeayNameNode</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SecondaryNameNode和NameNode的交互流程"><span class="toc-number">6.</span> <span class="toc-text">SecondaryNameNode和NameNode的交互流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NameNode-amp-DataNode的内存分配"><span class="toc-number">7.</span> <span class="toc-text">NameNode&amp;DataNode的内存分配</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/red.jpg"></div><div class="author-info__name text-center">Red</div><div class="author-info__description text-center">Developer</div><div class="follow-button"><a href="https://github.com/lvshaokang" target="_blank" rel="noopener">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">14</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">12</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">10</span></a></div></div></div><div id="content-outer"><div class="no-bg" id="top-container"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">RedのBlog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"></span></div><div id="post-info"><div id="post-title">为什么要改变HDFS tmp 文件存储目录&amp;整理块大小、副本数、小文件的理解&amp;整理HDFS架构&amp;整理SNN流程</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-09-21</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Hadoop/">Hadoop</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Hadoop/HDFS/">HDFS</a><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">1.7k</span><span class="post-meta__separator">|</span><span>Reading time: 6 min</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h3 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h3><ol>
<li>为什么要改变HDFS /tmp 存储目录</li>
<li>整理块大小、副本数的理解</li>
<li>整理小文件的理解</li>
<li>整理HDFS架构</li>
<li>整理SNN流程</li>
</ol>
<h3 id="为什么要改变HDFS-tmp-存储目录"><a href="#为什么要改变HDFS-tmp-存储目录" class="headerlink" title="为什么要改变HDFS /tmp 存储目录"></a>为什么要改变HDFS /tmp 存储目录</h3><p>HDFS NN/DN/SNN tmp文件存储目录默认是由<code>core-default.xml</code>中<code>hadoop.tmp.dir</code>参数决定的，如下：</p>
<table>
<thead>
<tr>
<th align="left">KEY</th>
<th>VALUE</th>
<th>DESC</th>
</tr>
</thead>
<tbody><tr>
<td align="left">hadoop.tmp.dir</td>
<td>/tmp/hadoop-${user.name}</td>
<td>A base for other temporary directories.</td>
</tr>
</tbody></table>
<p><strong>注：因为Linux的机制，/tmp 目录文件默认存储周期为1个月，超过1个月会自动清空不在规则以内的文件，为了防止文件丢失，我们需要改变hadoop的tmp文件存储目录</strong></p>
<ol>
<li>修改<code>core-site.xml</code>的<code>hadoop.tmp.dir</code>参数<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vi core-site.xml</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hadoop.tmp.dir&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;&#x2F;home&#x2F;hadoop&#x2F;tmp&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br></pre></td></tr></table></figure></li>
<li>修正权限<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">chmod -R 777 /home/ruoze/tmp</span><br><span class="line">mv /tmp/hadoop-ruoze/dfs /home/ruoze/tmp/</span><br></pre></td></tr></table></figure></li>
<li>重新启动hdfs<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">stop-dfs.sh</span><br><span class="line">start-dfs.sh</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h3 id="整理块大小、副本数的理解"><a href="#整理块大小、副本数的理解" class="headerlink" title="整理块大小、副本数的理解"></a>整理块大小、副本数的理解</h3><h4 id="块大小"><a href="#块大小" class="headerlink" title="块大小"></a>块大小</h4><p>hadoop 1.x 的块大小是64M，hadoop 2.x的块大小是128M，块大小是由<code>hdfs-default.xml</code>文件中<code>dfs.blocksize</code>参数控制。block是hdfs最小读写单元，它可以根据实际需求改变块大小，但一般不建议修改。</p>
<table>
<thead>
<tr>
<th align="left">KEY</th>
<th>VALUE</th>
<th>DESC</th>
</tr>
</thead>
<tbody><tr>
<td align="left">dfs.blocksize</td>
<td>134217728(128M)</td>
<td>The default block size for new files, in bytes. You can use the following suffix (case insensitive): k(kilo), m(mega), g(giga), t(tera), p(peta), e(exa) to specify the size (such as 128k, 512m, 1g, etc.), Or provide complete size in bytes (such as 134217728 for 128 MB).</td>
</tr>
</tbody></table>
<ul>
<li>块大小为什么要设计成128M?<br>因为目前磁盘的传输速率普遍是在100M/s左右，为了最小化寻址时间，所以设计成128M。</li>
</ul>
<h4 id="副本数"><a href="#副本数" class="headerlink" title="副本数"></a>副本数</h4><p>hdfs的副本的设计让hadoop具有高可用的特性，数据在不同节点存储多份，使数据不会轻易丢失。副本是存储在DN中的，由<code>hdfs-default.xml</code>文件中<code>dfs.replicatione</code>参数控制，副本数必须小于等于DN节点数，在伪分布式部署中，副本数为1；在集群部署中，副本数为3，可以根据实际需求修改，但一般不建议修改。</p>
<table>
<thead>
<tr>
<th align="left">KEY</th>
<th>VALUE</th>
<th>DESC</th>
</tr>
</thead>
<tbody><tr>
<td align="left">dfs.replication</td>
<td>3</td>
<td>Default block replication. The actual number of replications can be specified when the file is created. The default is used if replication is not specified in create time.</td>
</tr>
</tbody></table>
<h3 id="整理小文件的理解"><a href="#整理小文件的理解" class="headerlink" title="整理小文件的理解"></a>整理小文件的理解</h3><p>在生产中，一般情况下，小文件是指文件大小小于10M的文件，由于NN主要用来存储文件的元数据信息（在内存中），如果小文件数过多，那么对应小文件的block数也过多，那么NN需要维护的块的元数据信息也过多，又因为NN的内存大小有限，所以过多的小文件会对NN造成很大负载。<br>为了应对小文件过多的情况，一般情况下，我们选择<strong>把小文件合并成大文件在上传至hdfs上</strong>或者<strong>上传到hdfs后再合并</strong>，具体解决方案后面补充。</p>
<h3 id="整理HDFS的架构"><a href="#整理HDFS的架构" class="headerlink" title="整理HDFS的架构"></a>整理HDFS的架构</h3><p>HDFS由Client、NameNode、DataNode、SecondaryNameNode这四部分组成。</p>
<p>   <img src="/img/hdfs/HDFS-Architecture.png" alt="HDFS架构"></p>
<h4 id="NameNode"><a href="#NameNode" class="headerlink" title="NameNode"></a>NameNode</h4><p>NameNode 简写为NN，也被称为名称节点，它是HDFS主从架构中的老大，它主要用来存储文件系统的命名空间，且维护着整个文件系统的目录树以及目录树中所有子目录的文件的元数据信息。这些信息是以<strong>两个文件</strong>形式保存在本地磁盘上的，镜像文件fsimage和编辑日志文件editlog。文件系统的命名空间，如下：</p>
<ol>
<li>文件的名称</li>
<li>文件的目录结构</li>
<li>文件的属性、权限、创建时间、副本数</li>
<li><strong>文件对应被切分为哪些数据块（包含副本数），以及数据块分布在哪些DN节点上。</strong><br>说明：NN节点不会持久化存储这种映射关系，而是在集群启动和运行时，DN节点会定期向NN发送blockreport（默认间隔6小时，由<code>dfs.blockreport.intervalMsec</code>参数控制），NN节点接收到消息后，会在内存中动态维护这种映射关系。</li>
</ol>
<h4 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h4><p>DataNode 简写为DN，也被称为数据节点，它是HDFS主从架构中的小弟，它主要用来存储数据块和数据块校验和，这些信息是以Linux文件的形式保存在本地磁盘上的。DataNode会定期向NameNode发送心跳（默认3s）和块报告（默认6小时）。</p>
<ul>
<li><p>心跳<br>DN发送心跳是为了告诉NN我还活着，心跳间隔由<code>hdfs-default.xml</code>文件中的<code>dfs.heartbeat.interval</code>参数控制，默认每3s发送一次。</p>
<table>
<thead>
<tr>
<th>KEY</th>
<th>VALUE</th>
<th>DESC</th>
</tr>
</thead>
<tbody><tr>
<td>dfs.heartbeat.interval</td>
<td>3</td>
<td>Determines datanode heartbeat interval in seconds.</td>
</tr>
</tbody></table>
</li>
<li><p>块报告<br>DN发送块报告是为了扫描数据目录并协调内存和磁盘块之间的差异，块报告间隔由<code>hdfs-default.xml</code>文件中的<code>dfs.datanode.directoryscan.interval</code>参数和<code>dfs.blockreport.intervalMsec</code>参数控制的，默认每6小时发送一次。<br><strong>在生产环境中，建议缩短周期为3小时。</strong></p>
<table>
<thead>
<tr>
<th>KEY</th>
<th>VALUE</th>
<th align="left">DESC</th>
</tr>
</thead>
<tbody><tr>
<td>dfs.datanode.directoryscan.interval</td>
<td>21600</td>
<td align="left">Interval in seconds for Datanode to scan data directories and reconcile the difference between blocks in memory and on the disk.</td>
</tr>
<tr>
<td>dfs.blockreport.intervalMsec</td>
<td>21600000</td>
<td align="left">Determines block reporting interval in milliseconds.</td>
</tr>
</tbody></table>
</li>
</ul>
<h4 id="SecondeayNameNode"><a href="#SecondeayNameNode" class="headerlink" title="SecondeayNameNode"></a>SecondeayNameNode</h4><p>SecondeayNameNode 简写为SNN，也被称为第二名称节点，它是HDFS主从架构中的老二，它会定期合并<code>fsimage+editlog</code>文件，这个过程也被称为checkpoint。文件合并间隔是由<code>hdfs-default.xml</code>文件中的<code>dfs.namenode.checkpoint.period</code>参数（默认1小时）和<code>dfs.namenode.checkpoint.txns</code>参数（默认1000000条）控制的，两个参数满足其一即可触发合并机制。</p>
<table>
<thead>
<tr>
<th>KEY</th>
<th>VALUE</th>
<th align="left">DESC</th>
</tr>
</thead>
<tbody><tr>
<td>dfs.namenode.checkpoint.period</td>
<td>3600</td>
<td align="left">The number of seconds between two periodic checkpoints.</td>
</tr>
<tr>
<td>dfs.namenode.checkpoint.txns</td>
<td>1000000</td>
<td align="left">The Secondary NameNode or CheckpointNode will create a checkpoint of the namespace every ‘dfs.namenode.checkpoint.txns’ transactions, regardless of whether ‘dfs.namenode.checkpoint.period’ has expired.</td>
</tr>
</tbody></table>
<p><strong>注：虽然SNN能够减轻单点故障，但是还会有风险，因为在checkpoint完的下一个时间周期内发生故障，数据是恢复不了的</strong></p>
<h3 id="SecondaryNameNode和NameNode的交互流程"><a href="#SecondaryNameNode和NameNode的交互流程" class="headerlink" title="SecondaryNameNode和NameNode的交互流程"></a>SecondaryNameNode和NameNode的交互流程</h3><p>   <img src="/img/hdfs/NN-SNN.png" alt="SNN和NN的交互流程"></p>
<ol>
<li>NN滚动正在写入的editlog文件，并生成新的空的edits.new文件，并将以后的更新操作写入edits.new文件。</li>
<li>拷贝原来的editlog和fsimage文件到SNN</li>
<li>SNN把edits和fsimage文件加载到内存合并，生成新的镜像文件fsimage.ckpt</li>
<li>新生成的fsimage.ckpt文件会被拷贝到NN节点</li>
<li>fsimage.ckpt文件重命名为fsimage，并替换掉原来的fsimage.ckpt文件</li>
<li>edits.new文件重命名为edits，并替换掉原来的edits.new文件</li>
</ol>
<h3 id="NameNode-amp-DataNode的内存分配"><a href="#NameNode-amp-DataNode的内存分配" class="headerlink" title="NameNode&amp;DataNode的内存分配"></a><strong>NameNode&amp;DataNode的内存分配</strong></h3><p>建议DN进程分配2G，NM进程分配4G</p>
<ul>
<li><p>DN<br>我们生产上DN是设置8G，但是查看NN监控发现，使用率只要607M，经过长时间验证，只需配置2G即可<br> <img src="/img/hdfs/dn-monitor.png" alt="DN监控"></p>
</li>
<li><p>NN<br>NN的内存多少，和文件的个数有关系，因为一般来说一个文件一个块，在NN存储维护是150字节-250字节，所以设置NN为4G已经可以维护很多很多文件的元数据信息了，如果未来生产上真的数据文件特别多，那么找到维护时间，调大NN内存即可</p>
</li>
</ul>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Red</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://yoursite.com/2018/09/21/archives/hdfs/hdfs-1/">http://yoursite.com/2018/09/21/archives/hdfs/hdfs-1/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/HDFS/">HDFS</a><a class="post-meta__tags" href="/tags/Hadoop/">Hadoop</a></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2018/09/22/archives/hdfs/hdfs-2/"><i class="fa fa-chevron-left">  </i><span>HDFS读写流程&amp;Pid文件详解&amp;HDFS常用命令&amp;HDFS的回收站机制&amp;安全模式详解</span></a></div><div class="next-post pull-right"><a href="/2018/09/03/archives/linux/linux-1/"><span>Linux 基本操作及生产上如何定位Error日志</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2017 - 2021 By Red</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://lvshaokang.github.io" target="_blank" rel="noopener">blog</a>!</div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script></body></html>